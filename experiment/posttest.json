[
  {
    "question": "The single-layer perceptron can only learn linearly separable patterns because:",
    "answers": {
      "a": "It uses a linear activation function",
      "b": "It lacks hidden layers for complex feature representations",
      "c": "It cannot handle non-linear relationships",
      "d": "Both b) and c)"
    },
    "correctAnswer": "d"
  },
  {
    "question": "The single-layer perceptron algorithm can converge to a solution if:",
    "answers": {
      "a": "The data is linearly separable",
      "b": "The data is linearly non-separable",
      "c": "The learning rate is too high",
      "d": "The activation function is non-linear"
    },
    "correctAnswer": "a"
  },
  {
    "question": "The decision boundary of a single-layer perceptron is:",
    "answers": {
      "a": "Always linear",
      "b": "Always non-linear",
      "c": "Linear for linearly separable problems, non-linear otherwise",
      "d": "Non-linear for linearly separable problems, linear otherwise"
    },
    "correctAnswer": "c"
  },
  {
    "question": "How many output nodes are there in a Single Layer Perceptron designed for binary classification?",
    "answers": {
      "a": "One",
      "b": "Two",
      "c": "Depends on the input size",
      "d": "Variable"
    },
    "correctAnswer": "a"
  },
  {
    "question": "The perceptron learning rule updates the weights based on:",
    "answers": {
      "a": "The difference between the predicted output and the target output",
      "b": "The derivative of the activation function",
      "c": "The gradient of the cost function",
      "d": "The maximum likelihood estimation"
    },
    "correctAnswer": "a"
  }
]
